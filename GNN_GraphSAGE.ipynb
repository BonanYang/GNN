{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPEe4K5jo6FEDeyp31xgDnP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BonanYang/GNN/blob/main/GNN_GraphSAGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UmN5U_32XvLa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import scipy.sparse as sp\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "urllib.request.urlretrieve('https://data.dgl.ai/dataset/reddit.zip', 'reddit.zip')\n",
        "\n",
        "with zipfile.ZipFile('reddit.zip', 'r') as z:\n",
        "    z.extractall('reddit/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('reddit/reddit_data.npz')\n",
        "graph = np.load('reddit/reddit_graph.npz')"
      ],
      "metadata": {
        "id": "BCTPFLDqYAnN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(data['feature'][:10, :10]).round(2)\n",
        "df1['label'] = data['label'][:10]\n",
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkYQO670Y33W",
        "outputId": "2392bd17-18f8-4607-b89c-42450dc47c51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0     1     2     3     4     5     6     7     8     9  label\n",
            "0  1.23  9.04 -0.92  1.05 -1.11 -0.02  0.04  2.15 -0.91  0.71     30\n",
            "1 -0.14 -0.20  0.13 -0.42  0.11  0.30 -0.94 -0.98 -0.10  0.63     17\n",
            "2 -0.13 -0.20 -0.03  0.31  0.07  1.35  0.70 -0.66  1.14 -1.34     18\n",
            "3 -0.14 -0.20  0.18  0.57  0.37 -0.13 -0.13  0.39  1.67  0.05     23\n",
            "4 -0.16  0.01 -0.99  1.67  1.60 -0.30 -0.06  0.79 -0.78  0.74     22\n",
            "5 -0.13 -0.21  1.10  0.35  0.04 -0.08 -0.38 -1.02  0.45 -0.39     15\n",
            "6 -0.10 -0.19 -0.91 -0.30  0.20 -0.17 -0.52  0.34  0.00  0.34     33\n",
            "7 -0.14 -0.21 -2.06  0.07 -1.05 -0.56  0.53 -0.29  0.88 -1.09     14\n",
            "8 -0.16 -0.20  4.09  0.12 -0.90  2.71  1.37 -0.66 -0.85  1.28     38\n",
            "9 -0.16 -0.20  0.93  0.15  2.47  2.12 -2.59  0.61 -1.09 -1.56     18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "9MvtYzYqo14S",
        "outputId": "4f0fb48d-0c9f-4267-837f-adf8639d8a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1.23\n",
              "1         9.04\n",
              "2        -0.92\n",
              "3         1.05\n",
              "4        -1.11\n",
              "5        -0.02\n",
              "6         0.04\n",
              "7         2.15\n",
              "8        -0.91\n",
              "9         0.71\n",
              "label    30.00\n",
              "Name: 0, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data['feature'])\n",
        "df['label'] = data['label']"
      ],
      "metadata": {
        "id": "1yJwrByhonRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "1guBN2xNpjA3",
        "outputId": "13dc8fde-49df-480f-d468-fc067197c453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1.233415\n",
              "1         9.043012\n",
              "2        -0.923280\n",
              "3         1.054183\n",
              "4        -1.112501\n",
              "           ...    \n",
              "598      -0.443911\n",
              "599      -0.257895\n",
              "600       0.311193\n",
              "601      -0.377212\n",
              "label    30.000000\n",
              "Name: 0, Length: 603, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.233415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.043012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.923280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.054183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.112501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>-0.443911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>-0.257895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>0.311193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>-0.377212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>603 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj = sp.load_npz('reddit/reddit_graph.npz')\n",
        "print(type(adj))\n",
        "print(adj.shape)\n",
        "print(adj.nnz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLkTiOLhn_20",
        "outputId": "9634014c-d0e3-4fba-f14d-9cd94353ceea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._coo.coo_matrix'>\n",
            "(232965, 232965)\n",
            "114615892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "data = np.load('reddit/reddit_data.npz')\n",
        "features = torch.FloatTensor(data['feature'])\n",
        "labels = torch.LongTensor(data['label'])\n",
        "node_types = data['node_types']\n",
        "\n",
        "train_idx = np.where(node_types == 1)[0]\n",
        "val_idx = np.where(node_types == 2)[0]\n",
        "test_idx = np.where(node_types == 3)[0]\n",
        "\n",
        "class RedditDataset(Dataset):\n",
        "    def __init__(self, idx):\n",
        "        self.idx = idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        node_id = self.idx[i]\n",
        "        return features[node_id], labels[node_id]\n",
        "\n",
        "train_loader = DataLoader(RedditDataset(train_idx), batch_size=1024, shuffle=True)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, out_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MLP(602, 256, 41).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(batch_x), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_out = model(features[val_idx].to(device))\n",
        "        val_acc = (val_out.argmax(1) == labels[val_idx].to(device)).float().mean().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss/len(train_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_out = model(features[test_idx].to(device))\n",
        "    test_acc = (test_out.argmax(1) == labels[test_idx].to(device)).float().mean().item()\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8BKkoYwuS2e",
        "outputId": "2689f4a7-9657-4508-ed76-d60c5676ad5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Loss: 2.0036 | Val Acc: 0.5988\n",
            "Epoch 02 | Loss: 1.7953 | Val Acc: 0.6110\n",
            "Epoch 03 | Loss: 1.7420 | Val Acc: 0.6205\n",
            "Epoch 04 | Loss: 1.7227 | Val Acc: 0.6189\n",
            "Epoch 05 | Loss: 1.7086 | Val Acc: 0.6128\n",
            "Epoch 06 | Loss: 1.6862 | Val Acc: 0.6131\n",
            "Epoch 07 | Loss: 1.6782 | Val Acc: 0.6179\n",
            "Epoch 08 | Loss: 1.6724 | Val Acc: 0.6172\n",
            "Epoch 09 | Loss: 1.6597 | Val Acc: 0.6248\n",
            "Epoch 10 | Loss: 1.6807 | Val Acc: 0.6200\n",
            "Epoch 11 | Loss: 1.6773 | Val Acc: 0.6192\n",
            "Epoch 12 | Loss: 1.6757 | Val Acc: 0.6215\n",
            "Epoch 13 | Loss: 1.6746 | Val Acc: 0.6252\n",
            "Epoch 14 | Loss: 1.6711 | Val Acc: 0.6227\n",
            "Epoch 15 | Loss: 1.6718 | Val Acc: 0.6232\n",
            "Epoch 16 | Loss: 1.6498 | Val Acc: 0.6345\n",
            "Epoch 17 | Loss: 1.6535 | Val Acc: 0.6268\n",
            "Epoch 18 | Loss: 1.6590 | Val Acc: 0.6312\n",
            "Epoch 19 | Loss: 1.6506 | Val Acc: 0.6340\n",
            "Epoch 20 | Loss: 1.6374 | Val Acc: 0.6338\n",
            "Epoch 21 | Loss: 1.6447 | Val Acc: 0.6287\n",
            "Epoch 22 | Loss: 1.6432 | Val Acc: 0.6322\n",
            "Epoch 23 | Loss: 1.6200 | Val Acc: 0.6361\n",
            "Epoch 24 | Loss: 1.6227 | Val Acc: 0.6377\n",
            "Epoch 25 | Loss: 1.6142 | Val Acc: 0.6357\n",
            "Epoch 26 | Loss: 1.6266 | Val Acc: 0.6374\n",
            "Epoch 27 | Loss: 1.6085 | Val Acc: 0.6441\n",
            "Epoch 28 | Loss: 1.6205 | Val Acc: 0.6347\n",
            "Epoch 29 | Loss: 1.6164 | Val Acc: 0.6366\n",
            "Epoch 30 | Loss: 1.6081 | Val Acc: 0.6390\n",
            "Epoch 31 | Loss: 1.5944 | Val Acc: 0.6415\n",
            "Epoch 32 | Loss: 1.5956 | Val Acc: 0.6436\n",
            "Epoch 33 | Loss: 1.6009 | Val Acc: 0.6444\n",
            "Epoch 34 | Loss: 1.5975 | Val Acc: 0.6388\n",
            "Epoch 35 | Loss: 1.6048 | Val Acc: 0.6374\n",
            "Epoch 36 | Loss: 1.6004 | Val Acc: 0.6437\n",
            "Epoch 37 | Loss: 1.5966 | Val Acc: 0.6391\n",
            "Epoch 38 | Loss: 1.5982 | Val Acc: 0.6369\n",
            "Epoch 39 | Loss: 1.6029 | Val Acc: 0.6384\n",
            "Epoch 40 | Loss: 1.6183 | Val Acc: 0.6345\n",
            "Epoch 41 | Loss: 1.6006 | Val Acc: 0.6334\n",
            "Epoch 42 | Loss: 1.5931 | Val Acc: 0.6434\n",
            "Epoch 43 | Loss: 1.6034 | Val Acc: 0.6365\n",
            "Epoch 44 | Loss: 1.5889 | Val Acc: 0.6455\n",
            "Epoch 45 | Loss: 1.6039 | Val Acc: 0.6408\n",
            "Epoch 46 | Loss: 1.6079 | Val Acc: 0.6372\n",
            "Epoch 47 | Loss: 1.5902 | Val Acc: 0.6348\n",
            "Epoch 48 | Loss: 1.5887 | Val Acc: 0.6343\n",
            "Epoch 49 | Loss: 1.5821 | Val Acc: 0.6383\n",
            "Epoch 50 | Loss: 1.5728 | Val Acc: 0.6386\n",
            "Epoch 51 | Loss: 1.5824 | Val Acc: 0.6418\n",
            "Epoch 52 | Loss: 1.5847 | Val Acc: 0.6426\n",
            "Epoch 53 | Loss: 1.5883 | Val Acc: 0.6371\n",
            "Epoch 54 | Loss: 1.5866 | Val Acc: 0.6406\n",
            "Epoch 55 | Loss: 1.5722 | Val Acc: 0.6481\n",
            "Epoch 56 | Loss: 1.5675 | Val Acc: 0.6427\n",
            "Epoch 57 | Loss: 1.5779 | Val Acc: 0.6403\n",
            "Epoch 58 | Loss: 1.5666 | Val Acc: 0.6408\n",
            "Epoch 59 | Loss: 1.5717 | Val Acc: 0.6458\n",
            "Epoch 60 | Loss: 1.5835 | Val Acc: 0.6408\n",
            "Epoch 61 | Loss: 1.5743 | Val Acc: 0.6408\n",
            "Epoch 62 | Loss: 1.5912 | Val Acc: 0.6394\n",
            "Epoch 63 | Loss: 1.5708 | Val Acc: 0.6434\n",
            "Epoch 64 | Loss: 1.5818 | Val Acc: 0.6399\n",
            "Epoch 65 | Loss: 1.5717 | Val Acc: 0.6432\n",
            "Epoch 66 | Loss: 1.5692 | Val Acc: 0.6447\n",
            "Epoch 67 | Loss: 1.5667 | Val Acc: 0.6450\n",
            "Epoch 68 | Loss: 1.5585 | Val Acc: 0.6400\n",
            "Epoch 69 | Loss: 1.5585 | Val Acc: 0.6456\n",
            "Epoch 70 | Loss: 1.5673 | Val Acc: 0.6428\n",
            "Epoch 71 | Loss: 1.5671 | Val Acc: 0.6460\n",
            "Epoch 72 | Loss: 1.5534 | Val Acc: 0.6564\n",
            "Epoch 73 | Loss: 1.5608 | Val Acc: 0.6510\n",
            "Epoch 74 | Loss: 1.5850 | Val Acc: 0.6501\n",
            "Epoch 75 | Loss: 1.5838 | Val Acc: 0.6396\n",
            "Epoch 76 | Loss: 1.5688 | Val Acc: 0.6421\n",
            "Epoch 77 | Loss: 1.5595 | Val Acc: 0.6401\n",
            "Epoch 78 | Loss: 1.5675 | Val Acc: 0.6442\n",
            "Epoch 79 | Loss: 1.5667 | Val Acc: 0.6526\n",
            "Epoch 80 | Loss: 1.5520 | Val Acc: 0.6464\n",
            "Epoch 81 | Loss: 1.5603 | Val Acc: 0.6443\n",
            "Epoch 82 | Loss: 1.5631 | Val Acc: 0.6524\n",
            "Epoch 83 | Loss: 1.5643 | Val Acc: 0.6454\n",
            "Epoch 84 | Loss: 1.5762 | Val Acc: 0.6417\n",
            "Epoch 85 | Loss: 1.5603 | Val Acc: 0.6392\n",
            "Epoch 86 | Loss: 1.5536 | Val Acc: 0.6419\n",
            "Epoch 87 | Loss: 1.5609 | Val Acc: 0.6454\n",
            "Epoch 88 | Loss: 1.5593 | Val Acc: 0.6388\n",
            "Epoch 89 | Loss: 1.5624 | Val Acc: 0.6416\n",
            "Epoch 90 | Loss: 1.5490 | Val Acc: 0.6440\n",
            "Epoch 91 | Loss: 1.5485 | Val Acc: 0.6461\n",
            "Epoch 92 | Loss: 1.5592 | Val Acc: 0.6468\n",
            "Epoch 93 | Loss: 1.5485 | Val Acc: 0.6410\n",
            "Epoch 94 | Loss: 1.5561 | Val Acc: 0.6454\n",
            "Epoch 95 | Loss: 1.5444 | Val Acc: 0.6511\n",
            "Epoch 96 | Loss: 1.5538 | Val Acc: 0.6446\n",
            "Epoch 97 | Loss: 1.5739 | Val Acc: 0.6450\n",
            "Epoch 98 | Loss: 1.5626 | Val Acc: 0.6457\n",
            "Epoch 99 | Loss: 1.5752 | Val Acc: 0.6355\n",
            "Epoch 100 | Loss: 1.5754 | Val Acc: 0.6429\n",
            "\n",
            "Test Accuracy: 0.6408\n"
          ]
        }
      ]
    }
  ]
}