{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN5jFhXClttXUnPW68d1jnK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BonanYang/GNN/blob/main/Copy_of_GNN_GraphSAGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UmN5U_32XvLa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import scipy.sparse as sp\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve('https://data.dgl.ai/dataset/reddit.zip', 'reddit.zip')\n",
        "\n",
        "with zipfile.ZipFile('reddit.zip', 'r') as z:\n",
        "    z.extractall('reddit/')"
      ],
      "metadata": {
        "id": "4QnKDd6lBKTn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data at a glance"
      ],
      "metadata": {
        "id": "Py0VfKrkGrJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('reddit/reddit_data.npz')\n",
        "graph = np.load('reddit/reddit_graph.npz')"
      ],
      "metadata": {
        "id": "BCTPFLDqYAnN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(data['feature'][:10, :10]).round(2)\n",
        "df1['label'] = data['label'][:10]\n",
        "print(df1)"
      ],
      "metadata": {
        "id": "tkYQO670Y33W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c653b75-ed78-4414-8a52-902f02999de1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0     1     2     3     4     5     6     7     8     9  label\n",
            "0  1.23  9.04 -0.92  1.05 -1.11 -0.02  0.04  2.15 -0.91  0.71     30\n",
            "1 -0.14 -0.20  0.13 -0.42  0.11  0.30 -0.94 -0.98 -0.10  0.63     17\n",
            "2 -0.13 -0.20 -0.03  0.31  0.07  1.35  0.70 -0.66  1.14 -1.34     18\n",
            "3 -0.14 -0.20  0.18  0.57  0.37 -0.13 -0.13  0.39  1.67  0.05     23\n",
            "4 -0.16  0.01 -0.99  1.67  1.60 -0.30 -0.06  0.79 -0.78  0.74     22\n",
            "5 -0.13 -0.21  1.10  0.35  0.04 -0.08 -0.38 -1.02  0.45 -0.39     15\n",
            "6 -0.10 -0.19 -0.91 -0.30  0.20 -0.17 -0.52  0.34  0.00  0.34     33\n",
            "7 -0.14 -0.21 -2.06  0.07 -1.05 -0.56  0.53 -0.29  0.88 -1.09     14\n",
            "8 -0.16 -0.20  4.09  0.12 -0.90  2.71  1.37 -0.66 -0.85  1.28     38\n",
            "9 -0.16 -0.20  0.93  0.15  2.47  2.12 -2.59  0.61 -1.09 -1.56     18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.iloc[0]"
      ],
      "metadata": {
        "id": "9MvtYzYqo14S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "37720a2e-b8d5-4a8b-9816-a655fb8afc28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1.23\n",
              "1         9.04\n",
              "2        -0.92\n",
              "3         1.05\n",
              "4        -1.11\n",
              "5        -0.02\n",
              "6         0.04\n",
              "7         2.15\n",
              "8        -0.91\n",
              "9         0.71\n",
              "label    30.00\n",
              "Name: 0, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data['feature'])\n",
        "df['label'] = data['label']"
      ],
      "metadata": {
        "id": "1yJwrByhonRM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0]"
      ],
      "metadata": {
        "id": "1guBN2xNpjA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "4c02691b-3077-41cd-ae86-27cedad94151"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1.233415\n",
              "1         9.043012\n",
              "2        -0.923280\n",
              "3         1.054183\n",
              "4        -1.112501\n",
              "           ...    \n",
              "598      -0.443911\n",
              "599      -0.257895\n",
              "600       0.311193\n",
              "601      -0.377212\n",
              "label    30.000000\n",
              "Name: 0, Length: 603, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.233415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.043012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.923280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.054183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.112501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>-0.443911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>-0.257895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>0.311193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>-0.377212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>603 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj = sp.load_npz('reddit/reddit_graph.npz')\n",
        "print(type(adj))\n",
        "print(adj.shape)\n",
        "print(adj.nnz)"
      ],
      "metadata": {
        "id": "iLkTiOLhn_20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e449e0f-ffa3-4b6c-f5ce-da068284c5fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._coo.coo_matrix'>\n",
            "(232965, 232965)\n",
            "114615892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MLP"
      ],
      "metadata": {
        "id": "CjSdyqYK-d4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "data = np.load('reddit/reddit_data.npz')\n",
        "features = torch.FloatTensor(data['feature'])\n",
        "labels = torch.LongTensor(data['label'])\n",
        "node_types = data['node_types']\n",
        "\n",
        "train_idx = np.where(node_types == 1)[0]\n",
        "val_idx = np.where(node_types == 2)[0]\n",
        "test_idx = np.where(node_types == 3)[0]\n",
        "\n",
        "class RedditDataset(Dataset):\n",
        "    def __init__(self, idx):\n",
        "        self.idx = idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        node_id = self.idx[i]\n",
        "        return features[node_id], labels[node_id]\n",
        "\n",
        "train_loader = DataLoader(RedditDataset(train_idx), batch_size=1024, shuffle=True)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, out_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MLP(602, 256, 41).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(batch_x), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_out = model(features[val_idx].to(device))\n",
        "        val_acc = (val_out.argmax(1) == labels[val_idx].to(device)).float().mean().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss/len(train_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_out = model(features[test_idx].to(device))\n",
        "    test_acc = (test_out.argmax(1) == labels[test_idx].to(device)).float().mean().item()\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "U8BKkoYwuS2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GraphSAGE"
      ],
      "metadata": {
        "id": "xIOIFtJU-lT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data = np.load('reddit/reddit_data.npz')\n",
        "adj = sp.load_npz('reddit/reddit_graph.npz').tocsr()"
      ],
      "metadata": {
        "id": "LmHiFzbZCvqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSAGELayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(in_dim, out_dim)\n",
        "        self.B = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, X, self_idx, neigh_lists):\n",
        "        neighbor_feats = []\n",
        "        for neighs in neigh_lists:\n",
        "            if len(neighs) == 0:\n",
        "                neighbor_feats.append(torch.zeros(X.size(1), device=X.device))\n",
        "            else:\n",
        "                neighbor_feats.append(X[neighs].mean(dim=0))\n",
        "        neighbor_feats = torch.stack(neighbor_feats)\n",
        "        return self.W(neighbor_feats) + self.B(X[self_idx])\n",
        "\n",
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.sage1 = GraphSAGELayer(in_dim, hid_dim)\n",
        "        self.sage2 = GraphSAGELayer(hid_dim, out_dim)\n",
        "        self.S1, self.S2 = 25, 10\n",
        "\n",
        "    def sample(self, nodes, adj_list, size):\n",
        "        sampled = {}\n",
        "        for n in nodes:\n",
        "            neighs = adj_list[n]\n",
        "            if len(neighs) > size:\n",
        "                neighs = np.random.choice(neighs, size, replace=False).tolist()\n",
        "            sampled[n] = neighs\n",
        "        return sampled\n",
        "\n",
        "    def forward(self, X, batch, adj_list):\n",
        "        batch = list(batch)\n",
        "        batch_neighs = self.sample(batch, adj_list, self.S2)\n",
        "        L1_nodes = set(batch)\n",
        "        for neighs in batch_neighs.values():\n",
        "            L1_nodes.update(neighs)\n",
        "        L1_nodes = list(L1_nodes)\n",
        "        L1_neighs = self.sample(L1_nodes, adj_list, self.S1)\n",
        "        H1 = F.relu(self.sage1(X, L1_nodes, [L1_neighs[n] for n in L1_nodes]))\n",
        "\n",
        "        L1_map = {n: i for i, n in enumerate(L1_nodes)}\n",
        "        batch_idx = [L1_map[n] for n in batch]\n",
        "        neigh_idx = [[L1_map[nb] for nb in batch_neighs[n]] for n in batch]\n",
        "        H2 = self.sage2(H1, batch_idx, neigh_idx)\n",
        "\n",
        "        return H2"
      ],
      "metadata": {
        "id": "ZwIrax5y-no_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor(data['feature'])\n",
        "y = torch.LongTensor(data['label'])\n",
        "node_types = data['node_types']\n",
        "\n",
        "train_idx = np.where(node_types == 1)[0]\n",
        "val_idx = np.where(node_types == 2)[0]\n",
        "test_idx = np.where(node_types == 3)[0]\n",
        "\n",
        "adj_list = [adj[i].indices.tolist() for i in range(adj.shape[0])]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "X = X.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "model = GraphSAGE(602, 256, 41).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "batch_size = 512\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    np.random.shuffle(train_idx)\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(0, len(train_idx), batch_size):\n",
        "        batch_nodes = train_idx[i:i+batch_size]\n",
        "        out = model(X, batch_nodes, adj_list)\n",
        "        loss = F.cross_entropy(out, y[batch_nodes])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_out = model(X, val_idx, adj_list)\n",
        "        val_acc = (val_out.argmax(1) == y[val_idx]).float().mean().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss*batch_size/len(train_idx):.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_out = model(X, test_idx, adj_list)\n",
        "    test_acc = (test_out.argmax(1) == y[test_idx]).float().mean().item()\n",
        "print(f\"\\nTest Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "gwpqsds_-kkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"max node in adj_list: {max(max(adj_list[i]) if adj_list[i] else 0 for i in range(len(adj_list)))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBs67zLAGFMa",
        "outputId": "15b247c9-514c-442b-b381-6a75b518c6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([232965, 602])\n",
            "max node in adj_list: 232964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0Du8M_R1qVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modularity"
      ],
      "metadata": {
        "id": "fVLEhVkC1rOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-louvain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoYNd0jZ6JdP",
        "outputId": "c2634ec3-4158-482e-8535-6c6314a43814"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.12/dist-packages (0.16)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from python-louvain) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from python-louvain) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from collections import Counter\n",
        "# import community as community_louvain\n",
        "import networkx as nx\n",
        "from community import community_louvain\n",
        "\n",
        "data = np.load('reddit/reddit_data.npz')\n",
        "adj = sp.load_npz('reddit/reddit_graph.npz')\n",
        "\n",
        "labels = data['label']\n",
        "node_types = data['node_types']\n",
        "train_idx = np.where(node_types == 1)[0]\n",
        "val_idx = np.where(node_types == 2)[0]\n",
        "test_idx = np.where(node_types == 3)[0]\n",
        "\n",
        "G = nx.from_scipy_sparse_array(adj)\n",
        "partition = community_louvain.best_partition(G,resolution=4.0)\n",
        "clusters = np.array([partition[i] for i in range(len(partition))])\n",
        "\n",
        "cluster_to_label = {}\n",
        "for c in range(clusters.max() + 1):\n",
        "    mask = clusters[train_idx] == c\n",
        "    if mask.sum() > 0:\n",
        "        cluster_to_label[c] = Counter(labels[train_idx][mask]).most_common(1)[0][0]\n",
        "    else:\n",
        "        cluster_to_label[c] = 0\n",
        "\n",
        "pred = np.array([cluster_to_label[c] for c in clusters])\n",
        "\n",
        "print(f\"Val Acc: {(pred[val_idx] == labels[val_idx]).mean():.4f}\")\n",
        "print(f\"Test Acc: {(pred[test_idx] == labels[test_idx]).mean():.4f}\")\n",
        "print(f\"Communities: {clusters.max() + 1}, Classes: {len(np.unique(labels))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf0FbhQu1ulR",
        "outputId": "ad2382e3-764a-4f61-8df2-66757e46fd4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 0.6690\n",
            "Test Acc: 0.6694\n",
            "Communities: 26, Classes: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from collections import Counter\n",
        "# import community as community_louvain\n",
        "import networkx as nx\n",
        "from community import community_louvain\n",
        "\n",
        "data = np.load('reddit/reddit_data.npz')\n",
        "adj = sp.load_npz('reddit/reddit_graph.npz')\n",
        "\n",
        "labels = data['label']\n",
        "node_types = data['node_types']\n",
        "train_idx = np.where(node_types == 1)[0]\n",
        "val_idx = np.where(node_types == 2)[0]\n",
        "test_idx = np.where(node_types == 3)[0]\n",
        "\n",
        "G = nx.from_scipy_sparse_array(adj)\n",
        "partition = community_louvain.best_partition(G,resolution=4.0)\n",
        "clusters = np.array([partition[i] for i in range(len(partition))])\n",
        "\n",
        "cluster_to_label = {}\n",
        "for c in range(clusters.max() + 1):\n",
        "    mask = clusters[train_idx] == c\n",
        "    if mask.sum() > 0:\n",
        "        cluster_to_label[c] = Counter(labels[train_idx][mask]).most_common(1)[0][0]\n",
        "    else:\n",
        "        cluster_to_label[c] = 0\n",
        "\n",
        "pred = np.array([cluster_to_label[c] for c in clusters])\n",
        "\n",
        "print(f\"Val Acc: {(pred[val_idx] == labels[val_idx]).mean():.4f}\")\n",
        "print(f\"Test Acc: {(pred[test_idx] == labels[test_idx]).mean():.4f}\")\n",
        "print(f\"Communities: {clusters.max() + 1}, Classes: {len(np.unique(labels))}\")"
      ],
      "metadata": {
        "id": "_5P90xDcG-ZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}